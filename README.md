# Gemma 10M MLX

Gemma 2B with 10M context that runs on apple MLX. Our implementation uses **<32GB** of memory!

![Graphic of our implementation context](./images/graphic.png)

**Features**

- 10M sequence length on 2B Gemma.
- Runs on less then 32GB of memory.
- Native inference on apple silicon using MLX.
